{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLModels import LinearRegression, LogisticRegression, UnivariantLinearRegression, LDA, PCA\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.6251979825350213\n",
      "Y_hat:  4.109356342638097\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "\n",
    "x = np.array([[1,2,3],[0,1,1],[1,1,0],[1,0,1]]) # Dummy X_train\n",
    "y = np.array([2.4,5.6,2.3,2.7]) # Dummy Y_train\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x,y)\n",
    "print('Loss: ',model.loss) # Loss after final iteration\n",
    "\n",
    "print(\"Y_hat: \",model.predict(np.array([1,2,3]))) # Dummy X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Specifically, the KL divergence measures a very similar quantity to cross-entropy. It measures the average number of extra bits required to represent a message with Q instead of P, not the total number of bits.\n",
    "\n",
    "If two probability distributions are the same, then the cross-entropy between them will be the entropy of the distribution.\n",
    "\n",
    "[All about Cross Entropy, Entropy, Kl-Divergence, Log Loss](https://machinelearningmastery.com/cross-entropy-for-machine-learning/)\n",
    "\n",
    "**Log loss = negative log-likelihood (under a Bernoulli probability distribution)**\n",
    "\n",
    "`Cross_Entropy(Y,Y_hat) = Log_Loss(Y,Y_hat) = Entropy(Y) + KL_Divergence(Y,Y_hat)`\n",
    "\n",
    "`Cross_Entropy(Y,Y_hat) != Cross_Entropy(Y_hat,Y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0852763569399853\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "cla = LogisticRegression()\n",
    "y = np.array([1,0,0,1])\n",
    "cla.fit(x,y)\n",
    "\n",
    "print(cla.loss)\n",
    "\n",
    "prob, cla = cla.predict(np.array([1,2,3]))\n",
    "print(cla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.26470281, -0.4800266 , -0.12770602,  0.0241682 ],\n",
       "       [-2.08096115,  0.67413356, -0.23460885,  0.10300677],\n",
       "       [-2.36422905,  0.34190802,  0.04420148,  0.02837705]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA as PCA_sk\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  # we only take the first two features.\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "pca = PCA(4)\n",
    "pca.fit(X,transform=True)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.26470281,  0.4800266 , -0.12770602, -0.0241682 ],\n",
       "       [-2.08096115, -0.67413356, -0.23460885, -0.10300677],\n",
       "       [-2.36422905, -0.34190802,  0.04420148, -0.02837705]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_sk = PCA_sk(4,random_state=13)\n",
    "pca_sk.fit_transform(X)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([[-0.4,1.6,-0.3,1.3]])\n",
    "pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_sk.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_sk.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
