{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLModels import LinearRegression, LogisticRegression, UnivariantLinearRegression, LDA, PCA, KNN\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.6251979825350213\n",
      "Y_hat:  4.109356342638097\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "\n",
    "x = np.array([[1,2,3],[0,1,1],[1,1,0],[1,0,1]]) # Dummy X_train\n",
    "y = np.array([2.4,5.6,2.3,2.7]) # Dummy Y_train\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x,y)\n",
    "print('Loss: ',model.loss) # Loss after final iteration\n",
    "\n",
    "print(\"Y_hat: \",model.predict(np.array([1,2,3]))) # Dummy X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Specifically, the KL divergence measures a very similar quantity to cross-entropy. It measures the average number of extra bits required to represent a message with Q instead of P, not the total number of bits.\n",
    "\n",
    "If two probability distributions are the same, then the cross-entropy between them will be the entropy of the distribution.\n",
    "\n",
    "[All about Cross Entropy, Entropy, Kl-Divergence, Log Loss](https://machinelearningmastery.com/cross-entropy-for-machine-learning/)\n",
    "\n",
    "**Log loss = negative log-likelihood (under a Bernoulli probability distribution)**\n",
    "\n",
    "`Cross_Entropy(Y,Y_hat) = Log_Loss(Y,Y_hat) = Entropy(Y) + KL_Divergence(Y,Y_hat)`\n",
    "\n",
    "`Cross_Entropy(Y,Y_hat) != Cross_Entropy(Y_hat,Y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0852763569399853\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "cla = LogisticRegression()\n",
    "y = np.array([1,0,0,1])\n",
    "cla.fit(x,y)\n",
    "\n",
    "print(cla.loss)\n",
    "\n",
    "prob, cla = cla.predict(np.array([1,2,3]))\n",
    "print(cla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.26470281, -0.4800266 , -0.12770602,  0.0241682 ],\n",
       "       [-2.08096115,  0.67413356, -0.23460885,  0.10300677],\n",
       "       [-2.36422905,  0.34190802,  0.04420148,  0.02837705]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA as PCA_sk\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  # we only take the first two features.\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "pca = PCA(4)\n",
    "pca.fit(X,transform=True)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.26470281,  0.4800266 , -0.12770602, -0.0241682 ],\n",
       "       [-2.08096115, -0.67413356, -0.23460885, -0.10300677],\n",
       "       [-2.36422905, -0.34190802,  0.04420148, -0.02837705]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_sk = PCA_sk(4,random_state=13)\n",
    "pca_sk.fit_transform(X)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07919271, -1.40598311,  1.46075404,  0.61898115]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.array([[-0.4,1.6,-0.3,1.3]])\n",
    "pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07919271,  1.40598311,  1.46075404, -0.61898115]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_sk.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-3d89ebe961d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\ML Study\\ML Models from Scratch\\MLModels.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X_text)\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[0mX_test\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTest\u001b[0m \u001b[0mData\u001b[0m \u001b[0mfreatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         '''\n\u001b[1;32m--> 430\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "knn = KNN(k=3)\n",
    "x = np.array([[1,2,3],[3,4,5],[0,1,0]]) # Dummy X features\n",
    "y = np.array([0,1,0])\n",
    "x_test = np.array([[2,3,4]])\n",
    "\n",
    "knn.fit(x,y)\n",
    "knn.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
